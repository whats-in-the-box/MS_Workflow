---
title: "Metabolomics data processing"
author: "Max Qiu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: paper
    css: ../box_style.css

---

```{r knitr_opt, include = FALSE}
  knitr::opts_chunk$set(
    echo = FALSE,
    fig.width = 6
  )
```


```{r setup, message = FALSE, warning = FALSE, results = "hide"}
source("utils.R")
source("normalization.R")
source("univariate.R")
source("multivariate.R")

suppressPackageStartupMessages(c(
  library(tidyverse),
  library(ggplot2),
  library(pcaMethods),
  library(cowplot),
  library(statTarget),
  library(knitr),
  library(knitcitations),
  library(proBatch)
))
```


```{r setup_run,message = FALSE, warning = FALSE, results = "hide"}

FDR <- 0.05
LOG2FC <- 0
WORKING_DIR <- "wd1"
dir.create(file.path(WORKING_DIR))

# create an empty data frame to track missing data value
missing_df <- dplyr::tibble() %>%
  tibble::add_column(Stage = as.character(""),
                     No_of_missing = as.numeric(""))

```


# Project and data background

::: {.bluebox .caution data-latex="{caution}"}

Input background information for the project. Describe the experiment design, sample, data acquision and preprocessing steps. 
:::

# Batch Correction {.tabset .tabset-fade}

Batch correction using package `statTarget` evaluates the missing values and a feature will be kept if it has non-zero value for at least 50% of samples (`statTarget` default is 80%) in any one group. It then imputes missing values for the present features and QC-based signal correction. At last, it removes features CV% > 50% (default).


```{r upload.file, message=FALSE, warning=FALSE}

# user declared variables
pheno <- "C:/Users/qiuha/Documents/sources/repos/MS-Workflow/example_data/meta4samples.csv"
dfile = "C:/Users/qiuha/Documents/sources/repos/MS-Workflow/example_data/data4samples.csv"
#labels <- read.csv("C:/Users/qiuha/Documents/sources/repos/MS-Workflow/example_data/label4samples.csv", row.names = "SampleName")

message("Files have been uploaded. Batch Correction using statTarget will start soon. ")

statTarget::shiftCor(pheno, dfile,  QCspan = 0.25, Frule = 0.5,
                     degree = 2,imputeM = "KNN", ntree=500, coCV = 50)
# add NA number
dfile = read.csv(dfile)
missing_df <- track_missing("Raw file", sum(dfile == 0))
```



```{r upload.after.bc}

data_after_bc <- "statTarget/shiftCor/After_shiftCor/shift_sample_cor.csv"
fh <- upload.file(data_after_bc, 1) 

labels_d1 <- t(fh) %>%
        as.data.frame(.)%>%
        rownames_to_column(var = "rowname") %>%
        select(rowname, class) %>%
        column_to_rownames(var = "rowname") %>%
        `colnames<-`(., "Label") %>%
        as.matrix() 

message("After batch correction, there are ", (dim(fh)[1]-1), " features left.", sep = "\n")


fh %>%
  DT::datatable(., options = list(pagingType = "full_numbers",
                              pageLength = 10,
                              scrollX = "100%"), class = "nowrap")


```


The table below shows the number of missing values in the dataset at different stages of the workflow:


```{r}
# add NA number
missing_df <- track_missing("After batch correction", sum(is.na(fh)))

knitr::kable(missing_df, align = "c")
```




```{r message=FALSE, results=FALSE}
# draw histogram
d1 <- type.convert(fh[-1,])
hist_after_bc <- ggplot_truehist(unlist(d1), "After batch correction")
qq_after_bc <- ggplot_carqq(unlist(d1), "After batch correction")
pca_after_bc <- ggplot_pca(d1, labels_d1, "After batch correction")

# save data
#write.csv(imputed_d1, file.path(WORKING_DIR, "imputedData.csv"))
```


```{r summary.after.bc, fig.dim=c(18, 6), out.width= "100%", message = FALSE, warning = FALSE, results = "hide"}
#plot_grid(hist_after_bc, pca_after_bc, qq_after_bc, nrow = 1)
```


## Log2 transformation


```{r log2, message=FALSE, results=FALSE}
log2_d1 <- log2(type.convert(d1)) ## log2 transformation
# save data
#write.csv(log2_d1, file.path(WORKING_DIR, "log2_transformed.csv"))

# draw histogram
hist_log2 <- ggplot_truehist(unlist(log2_d1), "Log2 Transformed")
qq_log2 <- ggplot_carqq(unlist(log2_d1), "Log2 Transformed")
pca_log2 <- ggplot_pca(log2_d1, labels_d1, "Log2 Transformed")
```


```{r summary.log2, fig.dim=c(18, 6), out.width= "100%", message = FALSE, warning = FALSE, results = "hide"}
#plot_grid(hist_log2, pca_log2, qq_log2, nrow = 1)
```


```{r summary, fig.dim=c(10, 5), out.width= "100%",message=FALSE, results=FALSE}
plot_grid(hist_after_bc, pca_after_bc, qq_after_bc, hist_log2, pca_log2, qq_log2, nrow = 2)
```


## Peak intensity after log2 transformation


```{r message=FALSE, warning=FALSE, echo=FALSE}
library(proBatch)

meta = read.csv(pheno, header = TRUE)
color_list = sample_annotation_to_colors(meta, factor_columns = c("batch", "class"), numeric_columns = "order")
# after log2 transformation
log2_d1_long = matrix_to_long(log2_d1, sample_id_col = "sample")
plot_boxplot(log2_d1_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale)") # y-range = 45 for comparison purpose

```



# Normalization {.tabset .tabset-fade}


## EigenMS


**Data distribution**


```{r eigenMS, message=FALSE}
norm_eigenms <- do_normalization_short(log2_d1, labels_d1)

hist_eigenms <- ggplot_truehist(unlist(norm_eigenms[-1,]), "EigenMS")
qq_eigenms <- ggplot_carqq(unlist(norm_eigenms[-1,]), "EigenMS")
pca_eigenms <- ggplot_pca(norm_eigenms[-1,], labels_d1, "EigenMS")
```


```{r summary.eigenms, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_eigenms, qq_eigenms, pca_eigenms, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
norm_eigenms_mod = norm_eigenms[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


norm_eigenms_long = proBatch::matrix_to_long(norm_eigenms_mod, sample_id_col = "sample")
plot_boxplot(norm_eigenms_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


## Cubic Spline

**Data distribution**


```{r c_spline, message=FALSE, results=FALSE}
norm_cspline <- do_normalization_short(log2_d1, labels_d1, method = "Cubic Spline", samples = 0.02)

hist_cspline <- ggplot_truehist(unlist(norm_cspline[-1,]), "Cubic Spline")
qq_cspline <- ggplot_carqq(unlist(norm_cspline[-1,]), "Cubic Spline")
pca_cspline <- ggplot_pca(norm_cspline[-1,], labels_d1, "Cubic Spline")
```


```{r summary.cspline, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_cspline, qq_cspline, pca_cspline, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
norm_cspline_mod = norm_cspline[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


norm_cspline_long = proBatch::matrix_to_long(norm_cspline_mod, sample_id_col = "sample")
plot_boxplot(norm_cspline_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


## Invariant


**Data distribution**


```{r invariant, message=FALSE, results=FALSE}
#log2_d1 <- read.csv(file=file.path(WORKING_DIR, "log2_transformed.csv"),row.names = 1)
norm_invariant <- do_normalization_short(log2_d1, labels_d1, method = "Invariant")

hist_invariant <- ggplot_truehist(unlist(norm_invariant[-1,]), "Invariant")
qq_invariant <- ggplot_carqq(unlist(norm_invariant[-1,]), "Invariant")
pca_invariant <- ggplot_pca(norm_invariant[-1,], labels_d1, "Invariant")
```


```{r summary.invariant, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_invariant, qq_invariant, pca_invariant, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
norm_invariant_mod = norm_invariant[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


norm_invariant_long = proBatch::matrix_to_long(norm_invariant_mod, sample_id_col = "sample")
plot_boxplot(norm_invariant_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


# Pareto scaling {.tabset .tabset-fade}


## log2-pareto


**Data distribution**


```{r log2-scaling, message=FALSE}
log2_scale = MetabolAnalyze::scaling(type.convert(log2_d1), type = "pareto") %>%
  as.data.frame(.)
hist_log2_scale <- ggplot_truehist(unlist(log2_scale), "Pareto scaling")
qq_log2_scale <- ggplot_carqq(unlist(log2_scale), "Pareto scaling")
pca_log2_scale <- ggplot_pca(log2_scale, labels_d1, "Pareto scaling")
```


```{r summary.log2.scaling, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_log2_scale, qq_log2_scale, pca_log2_scale, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
log2_scale_long = matrix_to_long(log2_scale, sample_id_col = "sample")
plot_boxplot(log2_scale_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


## EigenMS-pareto


**Data distribution**


```{r eigenMS-scaling, message=FALSE}
eigenms_scale = MetabolAnalyze::scaling(type.convert(norm_eigenms[-1,]), type = "pareto") %>%
  as.data.frame(.) %>%
  rbind.data.frame("Label" = as.character(labels_d1),.)
hist_eigenms_scale <- ggplot_truehist(unlist(eigenms_scale[-1,]), "Pareto scaling")
qq_eigenms_scale <- ggplot_carqq(unlist(eigenms_scale[-1,]), "Pareto scaling")
pca_eigenms_scale <- ggplot_pca(eigenms_scale[-1,], labels_d1, "Pareto scaling")
```


```{r summary.eigenms.scaling, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_eigenms_scale, qq_eigenms_scale, pca_eigenms_scale, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
eigenms_scale_mod = eigenms_scale[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


eigenms_scale_long = proBatch::matrix_to_long(eigenms_scale_mod, sample_id_col = "sample")
plot_boxplot(eigenms_scale_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


## Cubic Spline-pareto


**Data distribution**


```{r c_spline-scaling, message=FALSE, results=FALSE}
cspline_scale = MetabolAnalyze::scaling(type.convert(norm_cspline[-1,]), type = "pareto") %>%
        as.data.frame(.) %>%
        rbind.data.frame("Label" = as.character(labels_d1),.)
hist_cspline_scale <- ggplot_truehist(unlist(cspline_scale[-1,]), "Cubic Spline")
qq_cspline_scale <- ggplot_carqq(unlist(cspline_scale[-1,]), "Cubic Spline")
pca_cspline_scale <- ggplot_pca(cspline_scale[-1,], labels_d1, "Cubic Spline")
```


```{r summary.cspline.scaling, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_cspline_scale, qq_cspline_scale, pca_cspline_scale, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
cspline_scale_mod = cspline_scale[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


cspline_scale_long = proBatch::matrix_to_long(cspline_scale_mod, sample_id_col = "sample")
plot_boxplot(cspline_scale_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


## Invariant-pareto


**Data distribution**


```{r invariant-scaling, message=FALSE, results=FALSE}
invariant_scale = MetabolAnalyze::scaling(type.convert(norm_invariant[-1,]), type = "pareto") %>%
        as.data.frame(.) %>%
        rbind.data.frame("Label" = as.character(labels_d1),.)
hist_invariant_scale <- ggplot_truehist(unlist(invariant_scale[-1,]), "Invariant")
qq_invariant_scale <- ggplot_carqq(unlist(invariant_scale[-1,]), "Invariant")
pca_invariant_scale <- ggplot_pca(invariant_scale[-1,], labels_d1, "Invariant")
```


```{r summary.invariant.scaling, fig.dim=c(18, 6), out.width="100%"}
plot_grid(hist_invariant_scale, qq_invariant_scale, pca_invariant_scale, nrow = 1)
```


**Peak intensity**


```{r message=FALSE, warning=FALSE, echo=FALSE}
invariant_scale_mod = invariant_scale[-1,] %>%
        as.data.frame() %>%
        rownames_to_column(., var = "rowname") %>%
        mutate(across(-rowname, as.numeric)) %>%
        column_to_rownames(., var = "rowname")


invariant_scale_long = proBatch::matrix_to_long(invariant_scale_mod, sample_id_col = "sample")
plot_boxplot(invariant_scale_long, meta, sample_id_col = "sample", batch_col = "batch", color_scheme = color_list[["batch"]], ylimits = c(-15,30)) + ylab("Intensity (log2 scale, after normalization)") # y-range = 45 for comparison purpose

```


# {.unlisted .unnumbered}


::: {.bluebox .caution data-latex="{caution}"}

Choose data processing method to proceed with statistical analysis. In this case, choose `log2-EigenMS` dataset to proceed with statistical analysis. 

:::


```{r choose_norm, echo = FALSE}
processingMethod <- "EigenMS"

processing_res <- list("EigenMS" = norm_eigenms, "EigenMS-Pareto" = eigenms_scale, "Cubic Spline" = norm_cspline, "Cubic Spline-Pareto" = cspline_scale, "Invariant" = norm_invariant,"Invariant-Pareto" = invariant_scale,"Pareto" = log2_scale)

```


# Univariate analysis {.tabset .tabset-fade}

Univariate statistic analysis will proceed for each pairs of comparison. For each pair,

Step 1, differential analysis;

* t-test

* Wilcoxon rank-sum test

For all statistical tests, the Benjamini-Hochberg (BH) procedure was applied to correct for multiple hypothesis testing. The table below shows results of univariate analysis. 

`pT` and `BHT`, *p* values and adjusted *p* values for Student's t-Test and `pW` and `BHW`, *p* values and adjusted *p* values for Wilcoxon Rank Sum Test.

Step 2, fold change, both linear and log2. 

The table below shows results of univariate analysis. 


```{r univariant, message=FALSE}
# first do data formatting
processed_df = processing_res[[processingMethod]]
# save data
#write.csv(processed_df, file.path(WORKING_DIR, "processed_data.csv"))


#save.image(file = "MS_workflow_BC_processing.RData")
```

