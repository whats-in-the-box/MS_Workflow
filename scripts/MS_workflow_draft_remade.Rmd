---
title: "MS Workflow draft"
author: 
- "BT"
- "CSL"
- "MQ"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: paper
    css: ../box_style.css
# runtime: shiny
---
```{r knitr_opt, include = FALSE}
  knitr::opts_chunk$set(
    echo = FALSE,
    fig.width = 6
  )
```

```{r setup, message = FALSE, warning = FALSE, results = "hide"}
source("assessFeatures.R")
source("uploadfile.R")
source("normality_check.R")
source("normalization.R")
source("univariate.R")
source("utils.R")
source("multivariate.R")

suppressPackageStartupMessages(c(
  library(tidyverse),
  library(ggplot2),
  library(pcaMethods),
  library(cowplot),
  library(shiny)
))
```

```{r setup_run}
# user declared variables
raw_data_file <- "C:/Users/qiuha/OneDrive - University of Nebraska-Lincoln/BCRF/DLSC_Projects/Checco/Unnormalized peak areas/peptide_unnormalized_NoDup.csv"

FDR <- 0.05
LOG2FC <- 0
WORKING_DIR <- "wd1"
dir.create(file.path(WORKING_DIR))

# create an empty data frame to track missing data value
missing_df <- dplyr::tibble() %>%
  tibble::add_column(Stage = as.character(""),
                     No_of_missing = as.numeric(""))

```

# Data Preparation and formatting {.tabset .tabset-fade}

Upload file... ...

```{r}
fh <- upload.file(raw_data_file, 1, 2:88)
message("The file: ", raw_data_file, " has been uploaded.", sep = "\n")
labels_d1 <- fh %>%
  rownames_to_column(var = "rowname") %>%
  select(Label, rowname) %>%
  column_to_rownames(var = "rowname") %>%
  as.matrix()
# add NA number
missing_df <- track_missing("Raw file", sum(fh == 0))
```



## Assess features and return present features


```{r}
raw.file <- presence.absence(fh)[,-c(1,2)]
# display data
raw.file %>%
  DT::datatable(., options = list(pagingType = "full_numbers",
                              pageLength = 10,
                              scrollX = "100%"),
            class = "nowrap")
# add NA number
missing_df <- track_missing("Before imputation", sum(is.na(raw.file)))

```


## Impute missing values


```{r}
# # compute k for impute.knn
# k <- raw.file %>% length() %>% sqrt()
# if (is.integer(k)) k = k else k = ceiling(k)
# k <- if_else(k >= 3, k, 3)
k = 7
imputed_meta_d1 <- impute::impute.knn(as.matrix(raw.file), k = k, rowmax = 0.5, 
                              colmax = 0.8, maxp = 1500)
imputed_d1 <- as.data.frame(imputed_meta_d1[["data"]], colnames = TRUE)
# draw histogram
# appropriate title? "Raw values after imputation"
(hist_imputed <- ggplot_truehist(unlist(imputed_d1), "Raw values after Imputation"))
(qq_imputed <- ggplot_carqq(unlist(imputed_d1), "Raw values after Imputation"))
(pca_imputed <- ggplot_pca(imputed_d1, labels_d1, "Raw values after Imputation"))
ggsave(file.path(WORKING_DIR, "PCA-Imputed.pdf"), pca_imputed, device = "pdf", width = 6, height = 6)
# save data
write.csv(imputed_d1, file.path(WORKING_DIR, "imputedData.csv"))
# add NA number
missing_df <- track_missing("After imputation", sum(imputed_d1==0))
```


The table below shows the number of missing values in the dataset 
at different stages of the workflow:


```{r}
knitr::kable(missing_df, align = "c")
```


todo: add batch correction - BT


## Log 2 transformation


```{r}
log2_d1 <- log2(type.convert(imputed_d1)) ## log2 transformation

# draw histogram
(hist_log2 <- ggplot_truehist(unlist(log2_d1), "Log2 Transformed"))
(qq_log2 <- ggplot_carqq(unlist(log2_d1), "Log2 Transformed"))
(pca_log2 <- ggplot_pca(log2_d1, labels_d1, "Log2 Transformed"))

ggsave(file.path(WORKING_DIR, "Histogram-log2transformedNoDup.pdf"), 
       hist_log2, device = "pdf", width = 10, height = 8)
```


# Check for missing data and normality before further processing


The table below shows the number of missing values in the dataset 
at different stages of the workflow:


```{r}
knitr::kable(missing_df, align = "c")
```

```{r, fig.dim = c(10, 5), out.width = "100%"}
plot_grid(hist_imputed, pca_imputed, qq_imputed, hist_log2, pca_log2, qq_log2, nrow = 2)
```

```{r norm_check1, include = FALSE, eval = FALSE}
normality_check(log2_d1)
```


# Normalization {.tabset .tabset-fade}


## EigenMS


```{r eigenMS, message = FALSE}
norm_eigenms <- do_normalization_short(log2_d1, labels_d1)
(hist_eigenms <- ggplot_truehist(unlist(norm_eigenms[-1,]), "EigenMS"))
(qq_eigenms <- ggplot_carqq(unlist(norm_eigenms[-1,]), "EigenMS"))
(pca_eigenms <- ggplot_pca(norm_eigenms[-1,], labels_d1, "EigenMS"))
```


## Cubic Spline


```{r c_spline, message = FALSE, results = FALSE}
norm_cspline <- do_normalization_short(log2_d1, labels_d1, method = "Cubic Spline")
(hist_cspline <- ggplot_truehist(unlist(norm_cspline[-1,]), "Cubic Spline"))
(qq_cspline <- ggplot_carqq(unlist(norm_cspline[-1,]), "Cubic Spline"))
(pca_cspline <- ggplot_pca(norm_cspline[-1,], labels_d1, "Cubic Spline"))
```


## Invariant


```{r invariant, message = FALSE, results = FALSE}
norm_invariant <- do_normalization_short(log2_d1, labels_d1, method = "Invariant")
(hist_invariant <- ggplot_truehist(unlist(norm_invariant[-1,]), "Invariant"))
(qq_invariant <- ggplot_carqq(unlist(norm_invariant[-1,]), "Invariant"))
(pca_invariant <- ggplot_pca(norm_invariant[-1,], labels_d1, "Invariant"))
```


# Normality check for different methods


```{r, fig.dim = c(18, 6), out.width = "100%"}
plot_grid(pca_eigenms, pca_cspline, pca_invariant, nrow = 1)
```


```{r, fig.dim = c(10, 5), out.width = "100%"}
plot_grid(hist_eigenms, hist_cspline, hist_invariant, nrow = 1)
```


```{r, fig.dim = c(10, 5), out.width = "100%"}
plot_grid(qq_eigenms, qq_cspline, qq_invariant, nrow = 1)
```

<!-- the below shiny block worked but cannot do what I have in mind -->

```{r, echo = FALSE, eval = FALSE}

selectInput(
  "norm_method", 
  "Which method to use for normalization?",
  list("EigenMS", "Cubic Spline", "Invariant"),
  )

renderText({
  paste(input$norm_method, " will be used for downstream analysis. ")
})
```

:::: {.bluebox data-latex=""}
::: {.center data-latex=""}
**ATTENTION**
:::

Please change the normalization method `norm_method` below to the chosen normalization method for downstream analysis:

::::


```{r choose_norm, echo = TRUE}
norm_method <- "EigenMS"

norm_res <- list("EigenMS" = norm_eigenms, "Cubic Spline" = norm_cspline, "Invariant" = norm_invariant) 
norm_log2_d1 <- norm_res[[norm_method]]
```


# Univariate 


The table below shows results of univariate analysis. 

`pT` and `BHT`, *p* values and adjusted *p* values for Student's t-Test and `pW` and `BHW`, *p* values and adjusted *p* values for Wilcoxon Rank Sum and Signed Rank Tests.


```{r univariate, message = FALSE}
# first do data formatting
d3_mod <- t(norm_log2_d1) %>%
  as_tibble() %>%
  mutate(across(-Label, as.numeric)) %>%
  rename_with(str_trim)

# then do univariate analysis
uni_res <- do_univariate(d3_mod)

# display table
uni_res %>%
  DT::datatable(., options = list(pagingType = "full_numbers",
                              pageLength = 10,
                              scrollX = "100%"),
            class = "nowrap")

```


```{r univariate_volcano, message = FALSE}
### volcano plot
# format univariate results tibble for plotting
uni_res <- uni_res %>%
  rowwise() %>%
  mutate(padj = min(c(BHT, BHW))) %>%
  # get the lowest padj
  ungroup() %>%
  mutate(`-log10padj` = -log(padj))

# get DE features only tibble
uni_res_filt <- uni_res %>%
  filter(BHT < FDR & BHW < FDR) %>%
  mutate(status = if_else("FC(log2)" < 0, "Down", "Up"))

# 1) volcano plot
deseq2_volcano(uni_res, uni_res_filt,
  fdr = FDR, log2fc = LOG2FC,
  "variable", padj_col = "padj", log2fc_col = "FC(log2)"
)
```


```{r univariate_hm, message = FALSE, fig.dim = c(16, 8), out.width = "100%"}
### heatmap
# prep the annotation for hm
anno <- data.frame(Label = as.factor(t(norm_log2_d1)[, "Label"]))

# prep the transformed matrix for hm
d1_mod <- norm_log2_d1[-1, ] %>%
  rownames_to_column("variable") %>%
  mutate(across(-variable, as.numeric))

# 2) heatmap
deseq2_hm(d1_mod, uni_res_filt, "variable", anno,
  top_n = NULL, col_order = NULL,
  save = FALSE, padj_col = NULL
)
```


```{r univariate_venn, message = FALSE}
### venn diagram
plot_set1 <- uni_res %>%
  filter(BHT < FDR) %>%
  pull(variable)
plot_set2 <- uni_res %>%
  filter(BHW < FDR) %>%
  pull(variable)
# v_data <- list("T Test" = plot_set1, "Wilcoxon Test" = plot_set2)
v_data <- list("Wilcoxon Test" = plot_set2, "T Test" = plot_set1)
make_venn(v_data)
```


# Multivariate {.tabset .tabset-fade}


```{r}
label = as.character(norm_log2_d1[1, ])
norm_log2_d1_mod <- norm_log2_d1[-1,] %>%
  rownames_to_column(.,var = "rowname") %>%
  mutate(across(-rowname, as.numeric)) %>%
  column_to_rownames(., var = "rowname")
```


## Outlier diagnostic


```{r detect_outliers, message = FALSE, results = "hide"}
# input overview
ropls::view(norm_log2_d1_mod)

# Outlier diagnostics
my.pca <- ropls::opls(as.data.frame(t(norm_log2_d1_mod)), 
                      parAsColFcVn = label, 
                      fig.pdfC = "none", 
                      info.txtC = "pca_info.txt")
plot(my.pca, typeVc = "outlier", parAsColFcVn = label, fig.pdfC = "interactive")
```


## PLS-DA 


:::: {.bluebox data-latex=""}
::: {.center data-latex=""}
**ATTENTION**
:::

Please change the outliers vector `outliers` below to the outliers detected above for PLS-DA analysis:

::::


```{r define_outliers, echo = TRUE}
outliers <- c("Sample_44")
```


### PLS-DA Full


```{r pls_da_full}
plsda_full <- pls_da(norm_log2_d1_mod, label)
plsda_full_res <- plsda_full[[1]]
plsda_full_plot <- plsda_full[[2]]
plsda_full_vip <- plsda_full[[3]]
```


### PLS-DA Partial, with no outliers


```{r pls_da_partial}
norm_log2_d1_mod_no_outlier <- norm_log2_d1_mod[ , !colnames(norm_log2_d1_mod) %in% outliers]
label_no_outlier <- t(norm_log2_d1[1, ])[!rownames(t(norm_log2_d1[1, ])) %in% outliers, ] %>% as.character()
plsda_partial <- pls_da(norm_log2_d1_mod_no_outlier, label_no_outlier)
plsda_partial_res <- plsda_partial[[1]]
plsda_partial_plot <- plsda_partial[[2]]
plsda_partial_vip <- plsda_partial[[3]]
```

### VIP comparison table

```{r pls_da_res}
# VIP table
tibble(
  "Full VIP" = names(plsda_full_vip),
  "Full score" = plsda_full_vip,
  "Partial VIP" = names(plsda_partial_vip),
  "Partial score" = plsda_partial_vip
) %>%   
  mutate(across(c("Full score", "Partial score"), ~round(.x, 4))) %>%
  DT::datatable(., options = list(pagingType = "full_numbers",
                              pageLength = 15),
                              # scrollX = "100%"),
            class = "nowrap")

```


## OPLS-DA


```{r opls_da}
my.oplsda <- ropls::opls(t(norm_log2_d1_mod), label, 
                         predI = 1, orthoI = NA, permI = 10, 
                         fig.pdfC = "none", info.txtC = "OPLS-DA_info.txt")
# OPLS-DA_overview
plot(my.oplsda, parAsColFcVn = label, fig.pdfC = "interactive")
# OPLS-DA scores
plot(my.oplsda, typeVc = "x-score", parAsColFcVn = label, 
     parLabVc = rep('o', length(label)), fig.pdfC = "interactive")
```


```{r, eval = FALSE}
do_multivariate(norm_log2_d1)
```
